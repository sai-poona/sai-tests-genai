{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import re\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(name)s : %(levelname)s : %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "def read_code(file_path):\n",
    "    logger.info(f'Reading code from {file_path}')\n",
    "    with open(file_path, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "def tokenize(content):\n",
    "    tokens = re.findall(r'\\b\\w+\\b', content)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 23:26:58,838 : __main__ : INFO : Reading code from ./sample_code/variation1/src/main/java/com/example/glue.java\n",
      "2024-05-24 23:26:58,841 : __main__ : INFO : Reading code from ./sample_code/variation2/src/main/java/com/example/glue.java\n",
      "2024-05-24 23:26:58,847 : __main__ : INFO : Reading code from ./sample_code/variation3/src/main/java/com/example/glue.java\n"
     ]
    }
   ],
   "source": [
    "common_file_path = 'src/main/java/com/example/glue.java'\n",
    "\n",
    "# Variations 1 and 3 were generated by the same GPT and Variation 2 was generated by a different GPT\n",
    "first_variation_path = f'./sample_code/variation1/{common_file_path}'\n",
    "second_variation_path = f'./sample_code/variation2/{common_file_path}'\n",
    "third_variation_path = f'./sample_code/variation3/{common_file_path}'\n",
    "\n",
    "variation1 = read_code(first_variation_path)\n",
    "variation2 = read_code(second_variation_path)\n",
    "variation3 = read_code(third_variation_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line count metric\n",
    "Count the number of lines in each implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 23:27:03,225 : __main__ : INFO : Lines in first implementation: 74\n",
      "2024-05-24 23:27:03,225 : __main__ : INFO : Lines in second implementation: 61\n",
      "2024-05-24 23:27:03,225 : __main__ : INFO : Lines in third implementation: 110\n"
     ]
    }
   ],
   "source": [
    "def count_lines(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return sum(1 for line in file if line.strip())\n",
    "\n",
    "implementation1 = count_lines(first_variation_path)\n",
    "implementation2 = count_lines(second_variation_path)\n",
    "implementation3 = count_lines(third_variation_path)\n",
    "\n",
    "logger.info(f'Lines in first implementation: {implementation1}')\n",
    "logger.info(f'Lines in second implementation: {implementation2}')\n",
    "logger.info(f'Lines in third implementation: {implementation3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cyclomatic complexity\n",
    "\n",
    "Measures the number of linearly-independent paths through a program module. Programs with lower Cyclomatic complexity are easier to understand and less risky to modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lizard\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 23:32:27,707 : __main__ : INFO : {\n",
      "    \"cyclomatic_complexity\": 1,\n",
      "    \"nloc\": 38,\n",
      "    \"token_count\": 354,\n",
      "    \"name\": \"GlueJob::main\",\n",
      "    \"long_name\": \"GlueJob::main( String [ ] args)\",\n",
      "    \"start_line\": 30,\n",
      "    \"end_line\": 88,\n",
      "    \"full_parameters\": [\n",
      "        \"String [ ] args\"\n",
      "    ],\n",
      "    \"filename\": \"./sample_code/variation1/src/main/java/com/example/glue.java\",\n",
      "    \"top_nesting_level\": 1,\n",
      "    \"fan_in\": 0,\n",
      "    \"fan_out\": 0,\n",
      "    \"general_fan_out\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "analyze_implementation1 = lizard.analyze_file(first_variation_path)\n",
    "logger.info(json.dumps(analyze_implementation1.function_list[0].__dict__, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 23:32:28,771 : __main__ : INFO : {\n",
      "    \"cyclomatic_complexity\": 2,\n",
      "    \"nloc\": 36,\n",
      "    \"token_count\": 259,\n",
      "    \"name\": \"GlueETLJob::main\",\n",
      "    \"long_name\": \"GlueETLJob::main( String [ ] args)\",\n",
      "    \"start_line\": 18,\n",
      "    \"end_line\": 67,\n",
      "    \"full_parameters\": [\n",
      "        \"String [ ] args\"\n",
      "    ],\n",
      "    \"filename\": \"./sample_code/variation2/src/main/java/com/example/glue.java\",\n",
      "    \"top_nesting_level\": 1,\n",
      "    \"fan_in\": 0,\n",
      "    \"fan_out\": 0,\n",
      "    \"general_fan_out\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "analyze_implementation2 = lizard.analyze_file(second_variation_path)\n",
    "logger.info(json.dumps(analyze_implementation2.function_list[0].__dict__, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 23:32:29,670 : __main__ : INFO : {\n",
      "    \"cyclomatic_complexity\": 1,\n",
      "    \"nloc\": 22,\n",
      "    \"token_count\": 147,\n",
      "    \"name\": \"GlueJobKCL::main\",\n",
      "    \"long_name\": \"GlueJobKCL::main( String [ ] args)\",\n",
      "    \"start_line\": 31,\n",
      "    \"end_line\": 62,\n",
      "    \"full_parameters\": [\n",
      "        \"String [ ] args\"\n",
      "    ],\n",
      "    \"filename\": \"./sample_code/variation3/src/main/java/com/example/glue.java\",\n",
      "    \"top_nesting_level\": 1,\n",
      "    \"fan_in\": 0,\n",
      "    \"fan_out\": 0,\n",
      "    \"general_fan_out\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "analyze_implementation3 = lizard.analyze_file(third_variation_path)\n",
    "logger.info(json.dumps(analyze_implementation3.function_list[0].__dict__, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity using `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim_count(first_code, second_code):\n",
    "    logger.info('Calculating cosine similarity using Count Vectorizer')\n",
    "    logger.info('Tokenizing first code')\n",
    "    first_code_tokens = ' '.join(tokenize(first_code))\n",
    "    logger.info('Tokenizing second code')\n",
    "    second_code_tokens = ' '.join(tokenize(second_code))\n",
    "\n",
    "    vect = CountVectorizer().fit_transform([first_code_tokens, second_code_tokens])\n",
    "    vectors = vect.toarray()\n",
    "\n",
    "    cosine_sim = cosine_similarity(vectors)\n",
    "    similarity = cosine_sim[0, 1] # Simlarity between first and second vectors\n",
    "    logger.info(f'Cosine similarity: {similarity}')\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 23:16:33,305 : __main__ : INFO : Calculating cosine similarity using Count Vectorizer\n",
      "2024-05-24 23:16:33,306 : __main__ : INFO : Tokenizing first code\n",
      "2024-05-24 23:16:33,307 : __main__ : INFO : Tokenizing second code\n",
      "2024-05-24 23:16:33,310 : __main__ : INFO : Cosine similarity: 0.8512908068064506\n"
     ]
    }
   ],
   "source": [
    "cosine_sim_count_score_12 = cosine_sim_count(variation1, variation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 23:16:39,605 : __main__ : INFO : Calculating cosine similarity using Count Vectorizer\n",
      "2024-05-24 23:16:39,606 : __main__ : INFO : Tokenizing first code\n",
      "2024-05-24 23:16:39,606 : __main__ : INFO : Tokenizing second code\n",
      "2024-05-24 23:16:39,608 : __main__ : INFO : Cosine similarity: 0.8724804327537654\n"
     ]
    }
   ],
   "source": [
    "cosine_sim_count_score_13 = cosine_sim_count(variation1, variation3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 23:16:41,642 : __main__ : INFO : Calculating cosine similarity using Count Vectorizer\n",
      "2024-05-24 23:16:41,643 : __main__ : INFO : Tokenizing first code\n",
      "2024-05-24 23:16:41,643 : __main__ : INFO : Tokenizing second code\n",
      "2024-05-24 23:16:41,645 : __main__ : INFO : Cosine similarity: 0.8168865148143062\n"
     ]
    }
   ],
   "source": [
    "cosine_sim_count_score_23 = cosine_sim_count(variation2, variation3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity using `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sim_tfidf(first_code, second_code):\n",
    "    logger.info('Calculating cosine similarity using Tfidf Vectorizer')\n",
    "    logger.info('Tokenizing first code')\n",
    "    first_code_tokens = ' '.join(tokenize(first_code))\n",
    "    logger.info('Tokenizing second code')\n",
    "    second_code_tokens = ' '.join(tokenize(second_code))\n",
    "\n",
    "    vect = TfidfVectorizer().fit_transform([first_code_tokens, second_code_tokens])\n",
    "    vectors = vect.toarray()\n",
    "\n",
    "    cosine_sim = cosine_similarity(vectors)\n",
    "    similarity = cosine_sim[0, 1] # Simlarity between first and second vectors\n",
    "    logger.info(f'Cosine similarity: {similarity}')\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 23:16:47,144 : __main__ : INFO : Calculating cosine similarity using Tfidf Vectorizer\n",
      "2024-05-24 23:16:47,144 : __main__ : INFO : Tokenizing first code\n",
      "2024-05-24 23:16:47,145 : __main__ : INFO : Tokenizing second code\n",
      "2024-05-24 23:16:47,147 : __main__ : INFO : Cosine similarity: 0.7674965341545423\n"
     ]
    }
   ],
   "source": [
    "cosine_sim_tfidf_score_12 = cosine_sim_tfidf(variation1, variation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 23:16:49,481 : __main__ : INFO : Calculating cosine similarity using Tfidf Vectorizer\n",
      "2024-05-24 23:16:49,482 : __main__ : INFO : Tokenizing first code\n",
      "2024-05-24 23:16:49,482 : __main__ : INFO : Tokenizing second code\n",
      "2024-05-24 23:16:49,484 : __main__ : INFO : Cosine similarity: 0.8163420018711519\n"
     ]
    }
   ],
   "source": [
    "cosine_sim_tfidf_score_13 = cosine_sim_tfidf(variation1, variation3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 23:16:50,906 : __main__ : INFO : Calculating cosine similarity using Tfidf Vectorizer\n",
      "2024-05-24 23:16:50,907 : __main__ : INFO : Tokenizing first code\n",
      "2024-05-24 23:16:50,907 : __main__ : INFO : Tokenizing second code\n",
      "2024-05-24 23:16:50,909 : __main__ : INFO : Cosine similarity: 0.739502588116892\n"
     ]
    }
   ],
   "source": [
    "cosine_sim_tfidf_score_23 = cosine_sim_tfidf(variation2, variation3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Levenshtein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "def levenshtein_distance(first_code, second_code):\n",
    "    logger.info('Calculating Levenshtein distance')\n",
    "    logger.info('Tokenizing first code')\n",
    "    first_code_tokens = ' '.join(tokenize(first_code))\n",
    "    logger.info('Tokenizing second code')\n",
    "    second_code_tokens = ' '.join(tokenize(second_code))\n",
    "    \n",
    "    distance = Levenshtein.distance(first_code_tokens, second_code_tokens)\n",
    "    logger.info(f'Levenshtein distance: {distance}')\n",
    "\n",
    "    ratio = Levenshtein.ratio(first_code_tokens, second_code_tokens)\n",
    "    logger.info(f'Levenshtein ratio: {ratio}')\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 23:16:56,834 : __main__ : INFO : Calculating Levenshtein distance\n",
      "2024-05-24 23:16:56,835 : __main__ : INFO : Tokenizing first code\n",
      "2024-05-24 23:16:56,836 : __main__ : INFO : Tokenizing second code\n",
      "2024-05-24 23:16:56,837 : __main__ : INFO : Levenshtein distance: 1841\n",
      "2024-05-24 23:16:56,838 : __main__ : INFO : Levenshtein ratio: 0.5758945386064029\n"
     ]
    }
   ],
   "source": [
    "levenshtein_distance_score_12 = levenshtein_distance(variation1, variation2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 23:17:00,392 : __main__ : INFO : Calculating Levenshtein distance\n",
      "2024-05-24 23:17:00,393 : __main__ : INFO : Tokenizing first code\n",
      "2024-05-24 23:17:00,394 : __main__ : INFO : Tokenizing second code\n",
      "2024-05-24 23:17:00,395 : __main__ : INFO : Levenshtein distance: 1606\n",
      "2024-05-24 23:17:00,395 : __main__ : INFO : Levenshtein ratio: 0.7330156569094622\n"
     ]
    }
   ],
   "source": [
    "levenshtein_distance_score_13 = levenshtein_distance(variation1, variation3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-24 23:17:09,681 : __main__ : INFO : Calculating Levenshtein distance\n",
      "2024-05-24 23:17:09,682 : __main__ : INFO : Tokenizing first code\n",
      "2024-05-24 23:17:09,682 : __main__ : INFO : Tokenizing second code\n",
      "2024-05-24 23:17:09,683 : __main__ : INFO : Levenshtein distance: 2719\n",
      "2024-05-24 23:17:09,684 : __main__ : INFO : Levenshtein ratio: 0.5058511468247777\n"
     ]
    }
   ],
   "source": [
    "levenshtein_distance_score_23 = levenshtein_distance(variation2, variation3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(code1, code2):\n",
    "    set1, set2 = set(code1.split()), set(code2.split())\n",
    "    return len(set1 & set2) / len(set1 | set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24242424242424243"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaccard_sim = jaccard_similarity(variation1, variation2)\n",
    "jaccard_sim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
